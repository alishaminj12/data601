50 Years of Data Science
  

Data Science has been around for more than 50 years. John Tukey, among others academic statistics, the future of data analysis, and coined his name. Data science was perceived differently and focused on data preparation and presentation over statistical modeling and interface. Colleges were offering courses in the Data Science Initiative (DSI) and hiring new faculty during mid-2015. As data science was blooming, statisticians were confused with the course similarity they have pursued in their careers. 

Initially, data science was not accepted and led to memes about big data, skills, and jobs. John Tukey published an article The Annals of Mathematical Statistics in 1960, which shocked the readers. And the same article is relevant to the concepts of today’s data science initiative, which identifies four major driving force that includes the theory of statistics, accelerating development, the challenges in vast data, and emphasis on quantification. His paper was not recognized right away, P. J. Huber explore Tukey’s vision in academic statistics. An article titled Statistical Modelling mentions that The Two Cultures by Leo Breiman simply predicted the future response of generating mechanisms and algorithms on datasets. And needless to say, his views were objected to by esteemed statisticians. 

The Author describes the secret sauce of machine learning as the combination of predictive modeling with a common task framework(CTF).
CTF skills are required by the developers in various technological features such as google translate, smartphone touch,  voice cognization, Netflix challenge. The above examples are using the CTF research paradigm. Recent Data Science Master’s degree programs are designed similar to the courses that are offered by the statistics department. Tukey, argues that focus should be given to data analysis and not arranging topics from different departments to create a quick degree course, compromising the including others who recognized data science.